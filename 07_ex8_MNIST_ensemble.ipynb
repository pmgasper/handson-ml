{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7, exercise 8\n",
    "\n",
    "MNIST ensemble learning\n",
    "* train, validation, test split (40,000 10,000 10,000)\n",
    "* Train various classifiers\n",
    "  + Random Forest\n",
    "  + Extra Trees\n",
    "  + SVM\n",
    "* Combine into an ensemble\n",
    "  + hard and soft voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "# Pandas\n",
    "pd.set_option('max_rows', 7)\n",
    "pd.set_option('max_columns', 50)\n",
    "\n",
    "# Numpy\n",
    "np.random.seed(42)  # to make this notebook's output stable across runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "# Get data\n",
    "#   hide warning about future depracation of fetch_mldata with v 0.22\n",
    "\n",
    "# Impore MNIST data\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', )\n",
    "X, y = mnist['data'].astype(float), mnist['target'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation / Test split\n",
    "  #  train vs. test specified by MNIST\n",
    "  #  train vs. validation with random shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_split = 60000\n",
    "\n",
    "X_train, y_train = X[:test_split], y[:test_split]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                   test_size=10000, random_state=42)\n",
    "\n",
    "X_test, y_test = X[test_split:], y[test_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial parameters - quick test\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=50, max_leaf_nodes=16, \n",
    "                                oob_score=True, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Out-of-Bag score\n",
    "rf_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=16,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=None,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa1454209b0>, 'max_leaf_nodes': [4, 8, 16, 32, None], 'max_features': ['sqrt', 'log2'], 'bootstrap': [True, False], 'oob_score': [False], 'criterion': ['gini', 'entropy']},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomized hyperparameter search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_iter = 20 \n",
    "\n",
    "param_dists = {'n_estimators': stats.randint(10, 100),\n",
    "               'max_leaf_nodes': [4, 8, 16, 32, None],\n",
    "               'max_features': ['sqrt', 'log2'],\n",
    "               'bootstrap': [True, False],\n",
    "               'oob_score': [False],\n",
    "               'criterion': ['gini', 'entropy']}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(rf_clf, param_dists, n_iter=n_iter, cv=3,\n",
    "                                return_train_score=True)\n",
    "\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters {'bootstrap': False, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'n_estimators': 67, 'oob_score': False}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>max_features</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>oob_score</th>\n",
       "      <th>criterion</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.96864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70</td>\n",
       "      <td>None</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.96656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>56</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.96310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.96202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.96070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>log2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.95672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators max_leaf_nodes max_features bootstrap oob_score criterion  \\\n",
       "0            67           None         sqrt     False     False      gini   \n",
       "5            70           None         sqrt     False     False   entropy   \n",
       "18           56           None         log2     False     False      gini   \n",
       "1            48           None         log2     False     False   entropy   \n",
       "6            84           None         log2      True     False      gini   \n",
       "16           38           None         log2      True     False      gini   \n",
       "\n",
       "      score  \n",
       "0   0.96864  \n",
       "5   0.96656  \n",
       "18  0.96310  \n",
       "1   0.96202  \n",
       "6   0.96070  \n",
       "16  0.95672  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter search results\n",
    "print('best parameters {0}'.format(rnd_search.best_params_))\n",
    "\n",
    "cvres = pd.DataFrame(rnd_search.cv_results_)\n",
    "param_names = list(param_dists.keys())\n",
    "cvres.rename({'param_' + key : key for key in param_names}, axis=1, inplace=True)\n",
    "cvres.rename({'mean_test_score':'score'}, axis=1, inplace=True)\n",
    "cvres[param_names + ['score']].sort_values(by='score', ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Hyperparameters from random search\n",
    "#   with some slection for speed amoung similarly high scores\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=50, max_leaf_nodes=None, \n",
    "                                max_features='sqrt', criterion='gini', \n",
    "                                oob_score=True, n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Out-of-Bag score\n",
    "rf_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.755"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial parameters - quick test\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "\n",
    "etree_clf = ExtraTreesClassifier(n_estimators=50, max_leaf_nodes=16, \n",
    "                                 bootstrap=True, oob_score=True, n_jobs=-1)\n",
    "\n",
    "etree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Out-of-Bag score\n",
    "etree_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized hyperparameter search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "n_iter = 20\n",
    "\n",
    "param_dists = {'n_estimators': stats.randint(10, 100),\n",
    "               'max_leaf_nodes': [4, 8, 16, 32, None],\n",
    "               'max_features': ['sqrt', 'log2'],\n",
    "               'bootstrap': [True, False],\n",
    "               'oob_score': [False],\n",
    "               'criterion': ['gini', 'entropy']}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(etree_clf, param_dists, n_iter=n_iter, cv=3,\n",
    "                                return_train_score=True)\n",
    "\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search results\n",
    "print('best parameters {0}'.format(rnd_search.best_params_))\n",
    "\n",
    "cvres = pd.DataFrame(rnd_search.cv_results_)\n",
    "param_names = list(param_dists.keys())\n",
    "cvres.rename({'param_' + key : key for key in param_names}, axis=1, inplace=True)\n",
    "cvres.rename({'mean_test_score':'score'}, axis=1, inplace=True)\n",
    "cvres[param_names + ['score']].sort_values(by='score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95466"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Hyperparameters from random search\n",
    "#   with some slection for speed amoung similarly high scores\n",
    "\n",
    "etree_clf = ExtraTreesClassifier(n_estimators=50, max_leaf_nodes=None, \n",
    "                                max_features='sqrt', criterion='gini', \n",
    "                                bootstrap=True, oob_score=True, n_jobs=-1)\n",
    "    \n",
    "etree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Out-of-Bag score\n",
    "etree_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SVC(C=25, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.0014, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using parameters identified in chapter 5, exercise 9\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "skip = 10   # subset for faster (though weaker) training\n",
    "\n",
    "svm_clf = Pipeline(\n",
    "    [('scale', StandardScaler()),\n",
    "     ('clf', SVC(C=25, gamma=0.0014, kernel='rbf', \n",
    "                 decision_function_shape='ovr'))])\n",
    "\n",
    "svm_clf.fit(X_train[::skip], y_train[::skip])\n",
    "\n",
    "# Cross-validation\n",
    "#cv_scores = cross_val_score(svm_clf, X_train[::skip], y_train[::skip], cv=5,\n",
    "#                            scoring=\"accuracy\")\n",
    "# print('{0:.3f} +/- {1:.3f}'.format(np.mean(cv_scores), np.std(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9618, 0.963, 0.9326]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Scores\n",
    "estimators = [rf_clf, etree_clf, svm_clf]\n",
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_we... max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine into voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Note: Invoking the fit method on the VotingClassifier will fit clones of \n",
    "#       those original estimators\n",
    "\n",
    "voting_clf = VotingClassifier([('rf', rf_clf), \n",
    "                               ('etree', etree_clf), \n",
    "                               ('svm', svm_clf)], \n",
    "                              voting='hard', n_jobs=-1)\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.9668\n",
      "ExtraTreesClassifier 0.9655\n",
      "Pipeline 0.9707\n",
      "VotingClassifier 0.9732\n"
     ]
    }
   ],
   "source": [
    "# Compare accuracy of individual classifiers and ensemble vote\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in voting_clf.estimators_ + [voting_clf]:\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n",
    "    \n",
    "# Note: pipeline = SVM pipeline\n",
    "# could rewrite to use names from voting_clf.named_estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "              oob_score=True, random_state=None, verbose=0, warm_start=False)),\n",
       " ('etree',\n",
       "  ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "             oob_score=True, random_state=None, verbose=0, warm_start=False)),\n",
       " ('svm', None)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove SVM classifier and perform soft voting\n",
    "# Note: For actual use, since SVM is performing well, would keep SVM and add \n",
    "#       hyperparameter probability=True, but here since SVM takes longest\n",
    "#       practice removing a classifier from ensemble\n",
    "\n",
    "voting_clf.set_params(svm=None)\n",
    "voting_clf.estimators  # Estimators not in use appear as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: list of trained estimators remains the same after setting svm to None\n",
    "# print(voting_clf.estimators_)\n",
    "\n",
    "# Avoid retraining voting_clf by removing SVM Pipeline from the list of \n",
    "# trained estimators (index 2)\n",
    "del voting_clf.estimators_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "             oob_score=True, random_state=None, verbose=0, warm_start=False),\n",
       " ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9605"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change voting to soft\n",
    "voting_clf.voting = 'soft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9658"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
